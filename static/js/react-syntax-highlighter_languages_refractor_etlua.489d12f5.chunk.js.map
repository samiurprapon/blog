{"version":3,"sources":["../node_modules/refractor/lang/markup-templating.js","../node_modules/refractor/lang/lua.js","../node_modules/refractor/lang/etlua.js"],"names":["markupTemplating","Prism","getPlaceholder","language","index","toUpperCase","Object","defineProperties","languages","buildPlaceholders","value","env","placeholderPattern","replaceFilter","tokenStack","code","replace","match","placeholder","i","length","indexOf","grammar","markup","tokenizePlaceholders","j","keys","walkTokens","tokens","token","content","k","t","s","before","substring","middle","Token","tokenize","after","replacement","push","apply","splice","concat","module","exports","displayName","aliases","lua","comment","string","pattern","greedy","number","keyword","function","operator","lookbehind","punctuation","refractorLua","require","refractorMarkupTemplating","etlua","register","delimiter","alias","inside","hooks","add"],"mappings":"uGAKA,SAASA,EAAiBC,IACvB,SAAWA,GAQV,SAASC,EAAeC,EAAUC,GAChC,MAAO,MAAQD,EAASE,cAAgBD,EAAQ,MAElDE,OAAOC,iBAAkBN,EAAMO,UAAU,qBAAuB,GAAK,CACnEC,kBAAmB,CAYjBC,MAAO,SAAUC,EAAKR,EAAUS,EAAoBC,GAClD,GAAIF,EAAIR,WAAaA,EAArB,CAGA,IAAIW,EAAcH,EAAIG,WAAa,GACnCH,EAAII,KAAOJ,EAAII,KAAKC,QAAQJ,GAAoB,SAAUK,GACxD,GAA6B,oBAAlBJ,IAAiCA,EAAcI,GACxD,OAAOA,EAIT,IAFA,IACIC,EADAC,EAAIL,EAAWM,QAIhB,IADDT,EAAII,KAAKM,QAASH,EAAchB,EAAeC,EAAUgB,OAGvDA,EAGJ,OADAL,EAAWK,GAAKF,EACTC,KAETP,EAAIW,QAAUrB,EAAMO,UAAUe,UAGlCC,qBAAsB,CAOpBd,MAAO,SAAUC,EAAKR,GACpB,GAAIQ,EAAIR,WAAaA,GAAaQ,EAAIG,WAAtC,CAGAH,EAAIW,QAAUrB,EAAMO,UAAUL,GAC9B,IAAIsB,EAAI,EACJC,EAAOpB,OAAOoB,KAAKf,EAAIG,aAC3B,SAASa,EAAWC,GAClB,IAAK,IAAIT,EAAI,EAAGA,EAAIS,EAAOR,UAErBK,GAAKC,EAAKN,QAFmBD,IAAK,CAKtC,IAAIU,EAAQD,EAAOT,GACnB,GACmB,kBAAVU,GACNA,EAAMC,SAAoC,kBAAlBD,EAAMC,QAC/B,CACA,IAAIC,EAAIL,EAAKD,GACTO,EAAIrB,EAAIG,WAAWiB,GACnBE,EAAqB,kBAAVJ,EAAqBA,EAAQA,EAAMC,QAC9CZ,EAAchB,EAAeC,EAAU4B,GACvC3B,EAAQ6B,EAAEZ,QAAQH,GACtB,GAAId,GAAS,EAAG,GACZqB,EACF,IAAIS,EAASD,EAAEE,UAAU,EAAG/B,GACxBgC,EAAS,IAAInC,EAAMoC,MACrBlC,EACAF,EAAMqC,SAASN,EAAGrB,EAAIW,SACtB,YAAcnB,EACd6B,GAEEO,EAAQN,EAAEE,UAAU/B,EAAQc,EAAYE,QACxCoB,EAAc,GACdN,GACFM,EAAYC,KAAKC,MAAMF,EAAab,EAAW,CAACO,KAElDM,EAAYC,KAAKL,GACbG,GACFC,EAAYC,KAAKC,MAAMF,EAAab,EAAW,CAACY,KAE7B,kBAAVV,EACTD,EAAOe,OAAOD,MAAMd,EAAQ,CAACT,EAAG,GAAGyB,OAAOJ,IAE1CX,EAAMC,QAAUU,QAIpBX,EAAMC,SAGNH,EAAWE,EAAMC,SAGrB,OAAOF,EAETD,CAAWhB,EAAIiB,aA9GtB,CAkHE3B,GAtHL4C,EAAOC,QAAU9C,EACjBA,EAAiB+C,YAAc,mBAC/B/C,EAAiBgD,QAAU,I,iCCC3B,SAASC,EAAIhD,GACXA,EAAMO,UAAUyC,IAAM,CACpBC,QAAS,yCAETC,OAAQ,CACNC,QACE,qFACFC,QAAQ,GAEVC,OACE,gHACFC,QACE,0HACFC,SAAU,2BACVC,SAAU,CACR,wCACA,CAEEL,QAAS,qBACTM,YAAY,IAGhBC,YAAa,uBAzBjBd,EAAOC,QAAUG,EACjBA,EAAIF,YAAc,MAClBE,EAAID,QAAU,I,iCCHd,IAAIY,EAAeC,EAAQ,KACvBC,EAA4BD,EAAQ,KAIxC,SAASE,EAAM9D,GACbA,EAAM+D,SAASJ,GACf3D,EAAM+D,SAASF,GACd,SAAW7D,GACVA,EAAMO,UAAUuD,MAAQ,CACtBE,UAAW,CACTb,QAAS,iBACTc,MAAO,eAET,eAAgB,CACdd,QAAS,UACTe,OAAQlE,EAAMO,UAAUyC,MAG5BhD,EAAMmE,MAAMC,IAAI,mBAAmB,SAAU1D,GAE3CV,EAAMO,UAAU,qBAAqBC,kBACnCE,EACA,QAHY,oBAOhBV,EAAMmE,MAAMC,IAAI,kBAAkB,SAAU1D,GAC1CV,EAAMO,UAAU,qBAAqBgB,qBAAqBb,EAAK,YApBlE,CAsBEV,GA5BL4C,EAAOC,QAAUiB,EACjBA,EAAMhB,YAAc,QACpBgB,EAAMf,QAAU","file":"static/js/react-syntax-highlighter_languages_refractor_etlua.489d12f5.chunk.js","sourcesContent":["'use strict'\n\nmodule.exports = markupTemplating\nmarkupTemplating.displayName = 'markupTemplating'\nmarkupTemplating.aliases = []\nfunction markupTemplating(Prism) {\n  ;(function (Prism) {\n    /**\n     * Returns the placeholder for the given language id and index.\n     *\n     * @param {string} language\n     * @param {string|number} index\n     * @returns {string}\n     */\n    function getPlaceholder(language, index) {\n      return '___' + language.toUpperCase() + index + '___'\n    }\n    Object.defineProperties((Prism.languages['markup-templating'] = {}), {\n      buildPlaceholders: {\n        /**\n         * Tokenize all inline templating expressions matching `placeholderPattern`.\n         *\n         * If `replaceFilter` is provided, only matches of `placeholderPattern` for which `replaceFilter` returns\n         * `true` will be replaced.\n         *\n         * @param {object} env The environment of the `before-tokenize` hook.\n         * @param {string} language The language id.\n         * @param {RegExp} placeholderPattern The matches of this pattern will be replaced by placeholders.\n         * @param {(match: string) => boolean} [replaceFilter]\n         */\n        value: function (env, language, placeholderPattern, replaceFilter) {\n          if (env.language !== language) {\n            return\n          }\n          var tokenStack = (env.tokenStack = [])\n          env.code = env.code.replace(placeholderPattern, function (match) {\n            if (typeof replaceFilter === 'function' && !replaceFilter(match)) {\n              return match\n            }\n            var i = tokenStack.length\n            var placeholder // Check for existing strings\n            while (\n              env.code.indexOf((placeholder = getPlaceholder(language, i))) !==\n              -1\n            ) {\n              ++i\n            } // Create a sparse array\n            tokenStack[i] = match\n            return placeholder\n          }) // Switch the grammar to markup\n          env.grammar = Prism.languages.markup\n        }\n      },\n      tokenizePlaceholders: {\n        /**\n         * Replace placeholders with proper tokens after tokenizing.\n         *\n         * @param {object} env The environment of the `after-tokenize` hook.\n         * @param {string} language The language id.\n         */\n        value: function (env, language) {\n          if (env.language !== language || !env.tokenStack) {\n            return\n          } // Switch the grammar back\n          env.grammar = Prism.languages[language]\n          var j = 0\n          var keys = Object.keys(env.tokenStack)\n          function walkTokens(tokens) {\n            for (var i = 0; i < tokens.length; i++) {\n              // all placeholders are replaced already\n              if (j >= keys.length) {\n                break\n              }\n              var token = tokens[i]\n              if (\n                typeof token === 'string' ||\n                (token.content && typeof token.content === 'string')\n              ) {\n                var k = keys[j]\n                var t = env.tokenStack[k]\n                var s = typeof token === 'string' ? token : token.content\n                var placeholder = getPlaceholder(language, k)\n                var index = s.indexOf(placeholder)\n                if (index > -1) {\n                  ++j\n                  var before = s.substring(0, index)\n                  var middle = new Prism.Token(\n                    language,\n                    Prism.tokenize(t, env.grammar),\n                    'language-' + language,\n                    t\n                  )\n                  var after = s.substring(index + placeholder.length)\n                  var replacement = []\n                  if (before) {\n                    replacement.push.apply(replacement, walkTokens([before]))\n                  }\n                  replacement.push(middle)\n                  if (after) {\n                    replacement.push.apply(replacement, walkTokens([after]))\n                  }\n                  if (typeof token === 'string') {\n                    tokens.splice.apply(tokens, [i, 1].concat(replacement))\n                  } else {\n                    token.content = replacement\n                  }\n                }\n              } else if (\n                token.content\n                /* && typeof token.content !== 'string' */\n              ) {\n                walkTokens(token.content)\n              }\n            }\n            return tokens\n          }\n          walkTokens(env.tokens)\n        }\n      }\n    })\n  })(Prism)\n}\n","'use strict'\n\nmodule.exports = lua\nlua.displayName = 'lua'\nlua.aliases = []\nfunction lua(Prism) {\n  Prism.languages.lua = {\n    comment: /^#!.+|--(?:\\[(=*)\\[[\\s\\S]*?\\]\\1\\]|.*)/m,\n    // \\z may be used to skip the following space\n    string: {\n      pattern:\n        /([\"'])(?:(?!\\1)[^\\\\\\r\\n]|\\\\z(?:\\r\\n|\\s)|\\\\(?:\\r\\n|[^z]))*\\1|\\[(=*)\\[[\\s\\S]*?\\]\\2\\]/,\n      greedy: true\n    },\n    number:\n      /\\b0x[a-f\\d]+(?:\\.[a-f\\d]*)?(?:p[+-]?\\d+)?\\b|\\b\\d+(?:\\.\\B|(?:\\.\\d*)?(?:e[+-]?\\d+)?\\b)|\\B\\.\\d+(?:e[+-]?\\d+)?\\b/i,\n    keyword:\n      /\\b(?:and|break|do|else|elseif|end|false|for|function|goto|if|in|local|nil|not|or|repeat|return|then|true|until|while)\\b/,\n    function: /(?!\\d)\\w+(?=\\s*(?:[({]))/,\n    operator: [\n      /[-+*%^&|#]|\\/\\/?|<[<=]?|>[>=]?|[=~]=?/,\n      {\n        // Match \"..\" but don't break \"...\"\n        pattern: /(^|[^.])\\.\\.(?!\\.)/,\n        lookbehind: true\n      }\n    ],\n    punctuation: /[\\[\\](){},;]|\\.+|:+/\n  }\n}\n","'use strict'\nvar refractorLua = require('./lua.js')\nvar refractorMarkupTemplating = require('./markup-templating.js')\nmodule.exports = etlua\netlua.displayName = 'etlua'\netlua.aliases = []\nfunction etlua(Prism) {\n  Prism.register(refractorLua)\n  Prism.register(refractorMarkupTemplating)\n  ;(function (Prism) {\n    Prism.languages.etlua = {\n      delimiter: {\n        pattern: /^<%[-=]?|-?%>$/,\n        alias: 'punctuation'\n      },\n      'language-lua': {\n        pattern: /[\\s\\S]+/,\n        inside: Prism.languages.lua\n      }\n    }\n    Prism.hooks.add('before-tokenize', function (env) {\n      var pattern = /<%[\\s\\S]+?%>/g\n      Prism.languages['markup-templating'].buildPlaceholders(\n        env,\n        'etlua',\n        pattern\n      )\n    })\n    Prism.hooks.add('after-tokenize', function (env) {\n      Prism.languages['markup-templating'].tokenizePlaceholders(env, 'etlua')\n    })\n  })(Prism)\n}\n"],"sourceRoot":""}